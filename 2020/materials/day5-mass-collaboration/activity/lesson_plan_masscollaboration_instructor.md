# Lesson Plan for Instructors
## Summer Institutes in Computational Social Science 2020
## Day 5, Mass collaboration
## Prepared by Matt Salganik and Ian Lundberg

This document assumes that you have also read the [lesson plan for participants](https://github.com/compsocialscience/summer-institute/blob/master/2020/materials/day5-mass-collaboration/activity/lesson_plan_masscollaboration_participant.md).

### Instructor preparation

Well in advance of the activity (we recommend at least two full days), participants will need to apply for data access. We recommend that you apply for data access even sooner so that you can help participants.

Familiarize yourself with the data files that you receive. They include components to support participants who may be falling behind, including a pre-prepared data file.

### Ethics: Guidelines for instructors

Remind your participants of the importance of using the data ethically. The reason projects like the Fragile Families Challenge are possible is because those who share their data trust that researchers will use it appropriately. As the local organizer, you have some power to set norms about holding the data in a secure location while working with it, not seeking to identify any individuals, and deleting the data when the analysis is complete.  We recommend that you remind participants to delete their data files at the end of the activity.

### Group formation

Form groups of roughly 3 people randomly. You might consider distributing those with the most predictive modeling experience across groups.

### A note about scoring

The [online submission site](https://codalab.fragilefamilieschallenge.org/competitions/28) scores submissions on the leaderboard set (530 cases, 1/8 of the sample). Participants are able to view their score on this set for each submission. In the original Challenge, we ultimately scored participants one time on the holdout set (1,591 cases). You may also want to score submissions on the holdout set one time at the end of the exercise. This will require manual coordination with the central organizers. If you want to do this, message Ian Lundberg to tell him the time at which your exercise will end. If we can coordinate the schedule successfully, Ian can score all submissions on the leaderboard at this time using the holdout data and email the scores to you. Because this is a manual process, it is possible that there will be problems.

If coordination is difficult, scoring on the holdout set may not be necessary. For pedagogical purposes, it may suffice for participants at SICSS to see their score on the leaderboard set, which will happen automatically in real time.

### How to debrief

In the debrief, here are some possible starter questions:

- How did you go about preparing the data file?
- Were there unexpected hurdles when preparing the data file? How did you address them? It is likely that groups took a range of approaches.
- How did you go about the predictive modeling exercise?
- What aspects of the exercise were successful from the standpoint of a participant?
- If you were organizing this mass collaboration, what would you change to make the experience better?
- Are there other questions we might tackle more successfully by working together than by working alone?

### Notes

- This activity is modular so you could just do the afternoon part using the data file that we have already prepared.
