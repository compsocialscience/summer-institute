---
title: "Non-probability-based Surveys in Practice"
author: Matthew Salganik and Cambria Naslund ^[based on the activities from SICSS 2017 (created by Matthew Salganik and Yo-Yo Chen) and SICSS 2018 (created by Matthew Salganik and Janet Xu).]
date: "Summer Institute in Computational Social Science 2019" 
output:
  html_document:
    df_print: paged
    toc: yes
---

```{r, echo=F}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Load packages and data

```{r, message = F, warning = F, echo = T }
# load packages
library(tidyverse)
library(lme4)

# set your working directory
# setwd("~/user/working_directory")

# load cleaned data file for survey results
data <- read.csv("https://github.com/compsocialscience/summer-institute/raw/master/2019/materials/day4-surveys/activity/2019-06-13_mturk_data_clean.csv")
## not using education or political attention check, so drop these vars
## (you can use these if you want!)
data <- data %>% select(-attention1, -educ)

## NOTE: if you are using your own survey results, you will need to 
## do some wrangling before you can match with the benchmark or acs data
## for a walkthrough, see https://github.com/compsocialscience/summer-institute/blob/master/2019/materials/day4-surveys/activity/mturk_data_cleaning.Rmd

# load external information -- in this case, population info
census <- read.csv("https://github.com/compsocialscience/summer-institute/raw/master/2019/materials/day4-surveys/activity/2017_acs_data_clean.csv")

# load pew benchmarks
pew <- read.csv("https://github.com/compsocialscience/summer-institute/raw/master/2019/materials/day4-surveys/activity/2019_pew_benchmark_data.csv", 
                col.names = c("qid", "label", "pew_estimate", "source"))
pew <- pew %>% select(qid, pew_estimate)
```

\newpage

# Approach 1: Simple means 

First, we'll just take the mean of the whole sample for each question. This approach doesn't use any post-stratification.

## 1.1) Calculate means

```{r}
# take the mean of survey responses in mturk data
## remove demographic variables (factor vars)
## get column means
mturk_means <- data %>% select(-sex, -race, -age_cat, -region) %>%
  summarise_all(~mean(., na.rm = T))

# reshape from wide to long
## with columns for questions (call this qid) and for mean
mturk_means <- mturk_means %>% gather(qid, mean)

# preview
head(mturk_means)
```

## 1.2) Plot estimated means against benchmarks

**Tip**: You will be making this type of plot each time you generate a new set of estimates, so it would be helpful to write a function for this.

```{r}

# merge mturk mean estimates with benchmark
mean_est <- inner_join(pew, mturk_means, by = c("qid"))
head(mean_est)

# make function for plot
plot_comparison <- function(est_table, method, caption){
  graph <-  ggplot(est_table, 
                   aes(x = pew_estimate, y = method)) + 
  geom_point() + 
  labs(x = "Estimates from Pew", y = caption) +
  scale_x_continuous(limits = c(0,1)) + 
  scale_y_continuous(limits = c(0,1)) + 
  geom_abline(intercept = 0, slope = 1, linetype = "dotted") + 
  coord_fixed()
  return(graph)
}  

# plot
plot_comparison(est_table = mean_est, 
                method = mean_est$mean, 
                caption = "Non-weighted estimates from MTurk")

```

## 1.3) Plot distribution of estimation-benchmark differences 

**Tip**: You will also be making this type of plot each time you generate a new set of estimates, so it would be helpful to write a function for this as well.

```{r}
# calculate difference
mean_est$diff <- abs(mean_est$mean - mean_est$pew_estimate)

# function for plotting difference
plot_diff <- function(est_table){
  diff_graph <- ggplot(est_table, aes(x = diff)) + 
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = .025, 
                 colour = "black", fill = "white") + 
  theme_bw() + 
  geom_vline(aes(xintercept = median(diff)), linetype = "longdash") + 
  labs(x = "absolute difference", y = "density") + 
  scale_y_continuous(limits = c(0, 0.45)) 
  return(diff_graph)
}

# plot
plot_diff(mean_est)
```

\newpage

# Approach 2: Means with post-stratification (8 groups)

## 2.1) Calculate group means, group weights, and weighted means

To start, group by sex and region only. This should give you 8 groups (2 sexes by 4 regions).

Group weights can be calculated as $\frac{N_{h}}{N}$. They should sum to 1. You will need to calculate these group weights for the other approaches as well. 

```{r}
# get total census population
N <- sum(census$POP)

# calculate group weights 
## group population data by sex and region,
## get the sum for each cell and divide by total pop
population_counts <- census %>% 
  group_by(sex, region) %>%
  summarise(group_weight = sum(POP)/N)

# check that weights sum to one
if (sum(population_counts$group_weight) != 1) {
  print("weights don't sum to one")
}

head(population_counts)

# calculate group means for each question response
## group data by sex and region
## remove non-numeric variables (demographic vars)
## calculate group means for each column
sample_counts <- data %>%
  group_by(sex, region) %>% 
  select_if(is.numeric) %>%
  summarise_all(list(~mean(.,na.rm = T)))

# preview -- scroll for more columns
head(sample_counts)

# check that there are no empty cells
if (nrow(sample_counts) < nrow(population_counts)) {
  print("GROUPS MISSING:")
  print(nrow(population_counts) - nrow(sample_counts))
}

# merge population counts with sample counts
# left join and retain all groups in population
cell_based <- left_join(population_counts, 
            sample_counts, 
            by = c("sex", "region"))

# reshape wide to long
cell_based_long <- cell_based %>% gather(qid, mean, 
                                         -c(sex, region, group_weight),
                                         na.rm = F)

head(cell_based_long)

# multiply the group means and group weights in the cell_based_long dataframe 
# and call this weighted_mean
cell_based_long <- mutate(cell_based_long, weighted_mean = group_weight*mean)

# sum weighted means, grouping by question
mturk_cell_est <- cell_based_long %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean, na.rm = T))


head(mturk_cell_est)
```

## 2.2) Plot estimated means against benchmarks

```{r}
# merge mturk cell-based weighted estimates with benchmark
simple_cell_est <- inner_join(pew, mturk_cell_est, by = c("qid"))
head(simple_cell_est)

#plot
plot_comparison(est_table = simple_cell_est, 
                method = simple_cell_est$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk")

```

## 2.3) Plot distribution of estimation-benchmark differences

```{r}
#calculate difference
simple_cell_est$diff <- abs(simple_cell_est$mturk_cell_estimate - simple_cell_est$pew_estimate)

#plot
plot_diff(simple_cell_est)
```


\newpage

# Approach 3: Means with post-stratification (160 groups) and missing group imputation

## 3.1) Calculate group means, group weights, and weighted means

Can you get better estimates grouping by more variables? Try grouping on sex, region, age group, and race. 

You will now have 160 groups (2 x 4 x 5 x 4). Some of groups may be missing from your sample (e.g. 50-64 year old black women in the midwest). If a group is missing, their answers will automatically be treated as "zero" when computing weighted means. As a result, some question responses may be underestimated. One way to deal with this is to impute the missing values with the sample average for that variable (aka the simple means we calculated in the first step). You will do this in the next step. 

First, calculate the new group means, group weights, and weighted means as you did above in Approach 2. 

```{r}
# get total population
N <- sum(census$POP)

# create weight by grouping by demographic categories,
# then summing each cell and dividing by total pop
population_counts <- census %>% 
  group_by(sex, region, age_cat, race) %>% 
  summarise(group_weight = sum(POP)/N)

# check that weights sum to one
if (sum(population_counts$group_weight) != 1) {
  print("weights don't sum to one")
}

# view
head(population_counts)
tail(population_counts)

# calculate group means for each question response
sample_counts <- data %>% 
  group_by(sex, region, age_cat, race) %>%
  summarise_all(list(~mean(.,na.rm = T)))

# preview -- scroll for more columns
head(sample_counts)

# check how many groups are missing
if (nrow(sample_counts) < nrow(population_counts)) {
  print("GROUPS MISSING:")
  print(nrow(population_counts) - nrow(sample_counts))
}

# merge population_counts with sample counts -- left join to retain all groups
# in population, even if not in sample
cell_based <- left_join(population_counts, 
            sample_counts, 
            by = c("sex", "region", "age_cat", "race"))

# reshape wide to long
cell_based_long <- cell_based %>% gather(qid, mean, 
                                         -c(sex, region, group_weight, age_cat, race),
                                         na.rm = F) 

head(cell_based_long)

# multiply the group means and group weights in the cell_based_long dataframe 
# and call this weighted_mean
cell_based_long <- mutate(cell_based_long, weighted_mean = group_weight*mean)

# then sum the group-specific weighted means, grouping by question
mturk_cell_est <- cell_based_long %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean, na.rm = T))


head(mturk_cell_est)

```

### 3.1.1) Dealing with missing groups: imputing with sample means

Now, replace the missing groups with the sample means you computed in 1.1. 

```{r}
# isolate missing groups:
missing_groups <- cell_based_long %>% filter(is.na(mean))

# merge sample means vector created in 1.1 (mturk_means) with this new dataframe
missing_groups_imputed <- inner_join(missing_groups, mturk_means, by = c("qid")) %>%
  select(-mean.x, -weighted_mean) %>%
  rename(mean = mean.y)

# now merge back with all non-missing groups (stored in cell_based_long)
cell_based_long_imputed <- right_join(missing_groups_imputed, cell_based_long,
                                     by = c("sex", "age_cat", "region", "race",
                                            "group_weight" , "qid")) %>%
                            mutate(mean = ifelse(is.na(mean.x), mean.y, mean.x)) %>%
                            select(-mean.x, -mean.y, -weighted_mean) %>%
# and recalculate weighted means  
                            mutate(weighted_mean_imputed = group_weight*mean)

# then sum the group-specific weighted means, grouping by question
cell_est_imputed <- cell_based_long_imputed %>% 
  group_by(qid) %>%
  summarise(mturk_cell_estimate = sum(weighted_mean_imputed, na.rm = T))

head(cell_est_imputed)

```

## 3.2) Plot estimated means against benchmarks

Plot both your new group means and the estimated means against the Pew benchmarks. 

```{r}
################################## WITH NO IMPUTATION ###################################
# merge mturk cell-based weighted estimates with benchmark
cell_based_est <- inner_join(pew, mturk_cell_est, by = c("qid"))
head(cell_based_est)

#plot
plot_comparison(est_table = cell_based_est, 
                method = cell_based_est$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk")

################################## WITH IMPUTATION ######################################
# merge mturk cell-based weighted estimates with benchmark
cell_est_imputed <- inner_join(pew, cell_est_imputed, by = c("qid"))
head(cell_est_imputed)

#plot
plot_comparison(est_table = cell_est_imputed, 
                method = cell_est_imputed$mturk_cell_estimate, 
                caption = "Cell-based weighted estimates from MTurk (with data imputation)")
```


## 3.3) Plot distribution of estimation-benchmark differences

```{r}
#################################### WITH NO IMPUTATION #################################
#calculate difference
cell_based_est$diff <- abs(cell_based_est$mturk_cell_estimate - cell_based_est$pew_estimate)

#plot
plot_diff(cell_based_est)

#################################### IMPUTATION #######################################

#calculate difference
cell_est_imputed$diff <- abs(cell_est_imputed$mturk_cell_estimate - cell_est_imputed$pew_estimate)

#plot
plot_diff(cell_est_imputed)
```

\newpage

# Approach 4: Model-based estimation with post-stratification

## 4.1) Predict group means with simple regression model; combine with group weights to create weighted means

```{r}
# for this, we will need convert everything into factors
data_factor <- data %>% mutate_all(funs(as.factor))

# Now we will regress each survey answer on demographic characteristics and
# use those model parameters to generate predicted probabilities for each group
# loop through each survey answer and store each vector of pred.probs
# in a 160 x 44 matrix 

# but first, write a warning function for later to make sure 
# that all estimates are 0 to 1 inclusive
prob_range_warning <- function(predictions){
  if (any(predictions < 0)) {
    warning("some predictions less than zero")
    } 
  if (any(predictions > 1)) {
    warning("some predictions more than one")
    } 
}

# create a character vector of the 44 question names
# these question names can be found in the column names of the data
relevant_questions <- colnames(data)[!colnames(data) %in% c("sex", "age_cat", "region", "race")]

# create container
model_predictions <- as.data.frame(matrix(nrow = nrow(population_counts), 
                                          ncol = length(relevant_questions), NA))
colnames(model_predictions) <- relevant_questions
# loop through
for (i in relevant_questions) {
  # get outcome
  outcome <- data_factor[ , i]
  # fit model
  model <- glm(outcome ~ sex + age_cat + region + race, 
             data = data_factor,
             family = binomial(link = "logit"))
  # create predicted probabilities
  reg_predicted_values <- predict(model, newdata = population_counts, type = "response")
  # check for errors
  prob_range_warning(reg_predicted_values)
  # store in container
  model_predictions[ , i] <- reg_predicted_values
}

# bind demographic categories to predictions
model_wide <- bind_cols(population_counts, model_predictions)
head(model_wide)

# reshape wide to long
model_long <- model_wide %>% gather(qid, predicted_value, 
                                         -c(sex, age_cat, region, race, group_weight),
                                         na.rm = F) 
head(model_long)

# weight predictions and sum by qid
model_est <- model_long %>%
  mutate(weighted_prediction = group_weight*predicted_value) %>%
  group_by(qid) %>%
  summarise(model_prediction = sum(weighted_prediction, na.rm = T)) 

head(model_est)

# merge with pew benchmarks
pew_model_est <- inner_join(pew, model_est, by = c("qid"))
```

## 4.2) Plot estimated means against benchmarks

```{r}
plot_comparison(est_table = pew_model_est,
                method = pew_model_est$model_prediction,
                caption = "Model-based predicted values") 
```

## 4.3) Plot distribution of estimation-benchmark differences 

```{r}
#calculate difference
pew_model_est$diff <- abs(pew_model_est$model_prediction - pew_model_est$pew_estimate)

#plot
plot_diff(pew_model_est)
```


\newpage

# Compare distribution of differences across methods and questions

Which questions worked well and which didn't? Which methods worked well for which questions?

```{r}
# put all differences into one table 
all_diff <- inner_join(mean_est, simple_cell_est, by = "qid") %>%
           select(qid, diff_mean = diff.x, diff_simple_cell = diff.y) %>%
              inner_join(., cell_based_est, by = "qid") %>%
              select(qid, diff_mean, diff_simple_cell, diff_cell = diff) %>%
              inner_join(., cell_est_imputed, by = "qid") %>%
              select(qid, diff_mean, diff_simple_cell, diff_cell, diff_cell_imputed = diff) %>%
                  inner_join(., pew_model_est, by = "qid") %>%
                  select(qid, diff_mean, diff_simple_cell, diff_cell, diff_cell_imputed, diff_model = diff)

# summarize
summary(all_diff, digits = 2)

# calculate MSE 
colMeans(apply(all_diff[ ,-1], 2, FUN = function(x){x^2}))

# calculate average difference across all methods for each question
all_diff$avg_diff <- apply(all_diff[ ,-1], 1, FUN = mean)
all_diff[,c("qid", "avg_diff")]
```

\newpage

# Optional Extension: \
  Approach 5: Multilevel-Model-based estimation with post-stratification (MRP)

### 5.1) Predict group means with multi-level regression model; combine with group weights to create weighted means

```{r}
## if using Bayesian estimation for multi-level model, you will need to load rstanarm
## note that Bayesian estimation is more computationally intensive/takes longer
# library(rstanarm)  

# create container
mrp_model_predictions <- as.data.frame(matrix(nrow = nrow(population_counts), 
                                          ncol = length(relevant_questions), NA))
colnames(mrp_model_predictions) <- relevant_questions

# loop through model fitting and prediction
for (i in relevant_questions) {
  outcome <- data_factor[ , i]
  # fit -- note that this is using default priors
  # nested the model name in "capture.out" to silently fit
  output <- capture.output(multilevel_model <-
                          glmer(outcome ~ sex + (1|age_cat) + (1|race) +
                          (1|region), data = data, family = binomial(link = "logit")))
  # predict
  mrp_predictions <- predict(multilevel_model,
                                       newdata = population_counts, type = "response")
  # errors?
  prob_range_warning(mrp_predictions)
  # feed into dataframe
  mrp_model_predictions[ , i] <- mrp_predictions
}

##################### Bayesian version with STAN #################################################

# library(rstanarm)
# 
# for (i in relevant_questions[1:2]) {
# outcome <- data_factor[ , i]
# # fit -- note that this is using default priors
# # nested the model name in "capture.out" to silently fit
# output <- capture.output(multilevel_model <- stan_glmer(outcome ~ sex + (1|age_cat) + (1|race) +
# (1|region), data = data, family = binomial(link = "logit"), adapt_delta = 0.99))
# # predict
# mrp_predictions <- posterior_linpred(multilevel_model,
# newdata = population_counts, type = "response")
# mrp_predictions_invlog <- exp(mrp_predictions)/(1 + exp(mrp_predictions))
# mrp_pred2 <- unname(apply(mrp_predictions_invlog, 2, mean))
# # errors?
# prob_range_warning(mrp_pred2)
# # feed into dataframe
# mrp_model_predictions[ , i] <- mrp_pred2
# }

# bind to demographic categories and group weights
mrp_wide <- bind_cols(population_counts, mrp_model_predictions)
head(mrp_wide)

# reshape wide to long
mrp_long <- mrp_wide %>% gather(qid, predicted_value, 
                                         -c(sex, age_cat, region, race, group_weight),
                                         na.rm = F) 
head(mrp_long)

# weigh, sum by qid, match with pew
mrp_est <- mrp_long %>%
  mutate(mrp_weighted_prediction = group_weight*predicted_value) %>%
  group_by(qid) %>%
  summarise(mrp_prediction = sum(mrp_weighted_prediction, na.rm = T)) 

head(mrp_est)

# merge with pew benchmarks
pew_mrp_est <- inner_join(pew, mrp_est, by = c("qid"))
```

### 5.2) Plot estimated means against benchmarks

```{r}
plot_comparison(est_table = pew_mrp_est,
                method = pew_mrp_est$mrp_prediction,
                caption = "MRP predicted values")
```

### 5.3) Plot distribution of estimation-benchmark differences

```{r}
#calculate difference
pew_mrp_est$diff <- abs(pew_mrp_est$mrp_prediction - pew_mrp_est$pew_estimate)

#plot
plot_diff(pew_mrp_est)
```

### 5.4) Compare differences from MRP with other methods

```{r}
# add mrp to table of differences
all_diff <- inner_join(all_diff, pew_mrp_est, by = "qid") %>%
                    select(qid, diff_mean, diff_simple_cell, diff_cell, diff_cell_imputed, diff_model, diff_mrp = diff)

# summarize
summary(all_diff, digits = 2)

# calculate MSE 
colMeans(apply(all_diff[ ,-1], 2, FUN = function(x){x^2}))
```
