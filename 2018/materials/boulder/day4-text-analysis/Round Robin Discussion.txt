Automated Text Analysis:
What is a text document for your research? What is a collection of documents?
Historical documents: 
Military rosters:
* Natural disasters!
        Anthropological journals:
* Mixed languages
* Geographical places and borders have changed over time “Gazetteer” in size or location or name


Social media:
Tweets
* How representative are tweets with respect to generalizing outside of tweets?
        Comments on YouTube
* Multi-language comments


TV transcripts: compared with ratings. More aggregated than we’d like.
* Transcription can be incorrect


Interview transcripts: how do you pick up sarcasm? Nuanced sentiment measures


Financial documents: reported yearly, mandated
* Standardized and relatively complete


Newspaper articles:
        “A Breast of the Market”: 1970 ish to present. Using sentiment analysis to look for relations to external finance shocks.


Presidential statements
* Messy and long depending on president
* How representative is a president’s speech with respect to the rest of the presidents?


Product reviews


Name disambiguation: “named entity recognition”
* Academic text: analyze citation network to help
* Gender classification: complicated by ethnicity


What is the context of these documents, and why might generic text processing fail? / What are the challenges or assumptions that out of the box text processing methods might make?


* Multi-language comments
* Language particular to a domain
* Named entity recognition
* Sarcasm:
   * We can learn keywords that are more closely related to negative or positive sentiment over time / by training on our particular dataset
* Interoperability / Authority control: 
   * The extension of relationships learned in one domain. How can we expand those to other domains
* Requires detailed manual annotation for the creation of ontologies
* Changes in naming due to external social changes
* Lack of control variables: understanding the demographic features of the speakers of your text